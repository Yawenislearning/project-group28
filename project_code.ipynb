{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geodatasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Documents/GitHub/project-group28/project_code.ipynb 单元格 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdb\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsycopg2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeodatasets\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlines\u001b[39;00m \u001b[39mimport\u001b[39;00m Line2D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geodatasets'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "import os\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import psycopg2\n",
    "import geodatasets\n",
    "import warnings\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.widgets import RangeSlider\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where data files will be read from/written to\n",
    "DATA_DIR = pathlib.Path(\"./data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"8ITaLVGKJEzelLCfrNyuIi2rJ\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "NYC_DATA_nypd='uip8-fykc.geojson'\n",
    "\n",
    "DB_NAME = \"project_database_final1\"\n",
    "DB_USER = \"qianzhuoxin\"\n",
    "DB_URL = f\"postgresql://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e9577",
   "metadata": {},
   "source": [
    "#### This section shows how we successfully load the five data files, we cleaned all the dataframes to clean, normalize and ensure the correct and consistent data types and dataframe types. We selected the columns based on the queries included in Part 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc932af6",
   "metadata": {},
   "source": [
    "#### Downloads a GeoJSON file from a specified URL and saves it with a given filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url: str, jsonname: str,force: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "        url: URL from which to download the GeoJSON data.\n",
    "        jsonname: filename where the downloaded data will be saved.\n",
    "        force: if set to True, the file will be downloaded again no matter whether it's existed.\n",
    "               False as default\n",
    "    \n",
    "    Returns:\n",
    "        the name of the file where the downloaded data is saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / (url_path.split('/')[-1])\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {jsonname}...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "       \n",
    "        with open(jsonname, \"a\") as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "    else:\n",
    "        print(f\"Reading from {jsonname}...\")\n",
    "\n",
    "    return jsonname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_311_data(df: pd.DataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        pandas dataframe\n",
    "    \n",
    "    Return: \n",
    "        A GeoDataFrame with cleaned and transformed 311 service request data\n",
    "    \"\"\"\n",
    "    columns = ['unique_key', 'created_date', 'incident_zip', 'complaint_type', 'longitude', 'latitude']\n",
    "    df_selected = df[columns]\n",
    "    df_selected = df_selected.dropna(axis = 0)\n",
    "    \n",
    "    df_selected.rename(columns = {'incident_zip': 'zipcode'}, inplace=True)\n",
    "    df_selected['zipcode'] = df_selected['zipcode'].astype(int)\n",
    "    df_selected.rename(columns = {'unique_key': 'id'}, inplace=True)\n",
    "    df_selected.rename(columns = {'created_date': 'date'}, inplace=True)\n",
    "    df_selected['geometry'] = gpd.points_from_xy(df_selected['longitude'], df_selected['latitude'], crs = \"EPSG:4326\")\n",
    "    df_selected = df_selected.drop(['latitude','longitude'],axis = 1)\n",
    "    df_selected['date'] = pd.to_datetime(df_selected['date']).dt.strftime('%Y-%m-%d')\n",
    "    df_selected['date'] = pd.to_datetime(df_selected['date']).dt.date\n",
    "    \n",
    "    return gpd.GeoDataFrame(df_selected,geometry = 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d355f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_311_data(offset: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        offset: show where data retrieval should start\n",
    "\n",
    "    Returns:\n",
    "        a pandas dataframe containing the downloaded 311 service request data\n",
    "    \"\"\"\n",
    "    base_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}?$$app_token={NYC_DATA_APP_TOKEN}\"\n",
    "    url = (\n",
    "        f'{base_url}&$limit=1000000&$offset={offset}'\n",
    "        f'&$where=created_date between \"2018-01-01T12:00:00.000\" '\n",
    "        f'and \"2023-09-30T12:00:00.000\"'\n",
    "    )\n",
    "    download_nyc_geojson_data(\n",
    "        url, jsonname=f'query_{offset/1000000+1}_data.geojson', force=False\n",
    "    )\n",
    "    print('begin to create csv')\n",
    "    df = gpd.read_file(f'query_{offset/1000000+1}_data.geojson')\n",
    "    print('finishing create csv')\n",
    "    csv_filename = f'query_{offset/1000000+1}_data.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    return pd.read_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59d7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_311_data(offset:int = 1000000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        offset: show where data retrieval should start\n",
    "\n",
    "    Returns:\n",
    "        a pandas dataframe containing the downloaded 311 service request data\n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "        filename = f\"query_{i}_data.csv\"\n",
    "        pathname = DATA_DIR / 'data311'/filename\n",
    "        if pathname.exists():\n",
    "            df = pd.read_csv(pathname)\n",
    "        else:\n",
    "            df = download_311_data(i*offset)\n",
    "        if i == 1:\n",
    "            df_311 = df\n",
    "        else:\n",
    "            df_311 = pd.concat([df_311,df])\n",
    "        flag = df.shape[0]==offset\n",
    "        i += 1\n",
    "    return clean_311_data(df_311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa407bd",
   "metadata": {},
   "source": [
    "### zipcode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4005f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(ZIPCODE_DATA_FILE: pathlib.PosixPath) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        zipcode_datafile: The file path to the geospatial data file\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: a cleaned and processed GeoDataFrame\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(ZIPCODE_DATA_FILE)\n",
    "    #normalized data\n",
    "    gdf_normalized = gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    #selected_zipcode\n",
    "    columns=['ZIPCODE', 'PO_NAME', 'STATE','COUNTY','geometry']\n",
    "    gdf_selected=gdf_normalized[columns]\n",
    "    gdf_selected.rename(columns={'ZIPCODE': 'zipcode'}, inplace=True)\n",
    "    gdf_selected.rename(columns={'COUNTY': 'county'}, inplace=True)\n",
    "    gdf_selected.rename(columns={'STATE': 'state'}, inplace=True)\n",
    "    gdf_selected.rename(columns={'PO_NAME': 'poname'}, inplace=True)\n",
    "    \n",
    "    #cleaned_zipcode\n",
    "    gdf_cleaned = gdf_selected.dropna()\n",
    "    gdf_cleaned.insert(0,\"id\", gdf_cleaned.index)\n",
    "    return gdf_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ef4b9",
   "metadata": {},
   "source": [
    "### tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde1b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tree_data():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        a pandas DataFrame containing the tree data downloaded from the NYC Open Data source.\n",
    "    \"\"\"\n",
    "    base_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}?$$app_token={NYC_DATA_APP_TOKEN}\"\n",
    "    url = f'{base_url}&$limit=1000000'\n",
    "    download_nyc_geojson_data(url,jsonname = 'nyc_tree.geojson',force = False)\n",
    "    df = gpd.read_file('nyc_tree.geojson')\n",
    "    df.to_csv('nyc_tree.csv',index = False)\n",
    "    \n",
    "    df_read = pd.read_csv(\"nyc_tree.csv\")\n",
    "    return df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217b7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tree_data(df: pd.DataFrame) -> gpd.GeoDataFrame: \n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        pandas dataframe\n",
    "    \n",
    "    Return: \n",
    "        A GeoDataFrame with cleaned and transformed tree data\n",
    "    \"\"\"\n",
    "    columns = ['tree_id','zipcode','longitude', 'latitude','spc_common','health','status']\n",
    "    df_selected = df[columns]\n",
    "    df_selected.rename(columns = {'tree_id': 'id'}, inplace = True)\n",
    "    df_selected['geometry'] = gpd.points_from_xy(df_selected['longitude'],df_selected['latitude'],crs = \"EPSG:4326\")\n",
    "    \n",
    "    df_drop = df_selected.drop(['latitude','longitude'],axis = 1)\n",
    "    df_cleaned = df_drop.dropna()\n",
    "    return gpd.GeoDataFrame(df_cleaned,geometry = 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f501d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tree_data() -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        a geopandas dataframe containing the downloaded 311 service request data\n",
    "    \"\"\"\n",
    "    filename = \"nyc_tree.csv\"\n",
    "    pathname = DATA_DIR / filename\n",
    "    if pathname.exists():\n",
    "        df = pd.read_csv(pathname)\n",
    "    else:\n",
    "        df = download_tree_data()\n",
    "    return clean_tree_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340db03e",
   "metadata": {},
   "source": [
    "### zillow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efddc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(ZILLOW_DATA_FILE: pathlib.PosixPath) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        zipcode_datafile: The file path to the geospatial data file\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: a cleaned and processed GeoDataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    # Only choose NY data\n",
    "    filtered_df = df[df['City'] == 'New York']\n",
    "    \n",
    "    # Change data from wide to long\n",
    "    df_melt = filtered_df.melt(id_vars = ['RegionName'],value_vars = ['2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31',\n",
    "       '2015-06-30', '2015-07-31', '2015-08-31', '2015-09-30', '2015-10-31','2015-11-30',\n",
    "       '2015-12-31', '2016-01-31', '2016-02-29', '2016-03-31', '2016-04-30',\n",
    "       '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30',\n",
    "       '2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28',\n",
    "       '2017-03-31', '2017-04-30', '2017-05-31', '2017-06-30', '2017-07-31',\n",
    "       '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30', '2017-12-31',\n",
    "       '2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30', '2018-05-31',\n",
    "       '2018-06-30', '2018-07-31', '2018-08-31', '2018-09-30', '2018-10-31',\n",
    "       '2018-11-30', '2018-12-31', '2019-01-31', '2019-02-28', '2019-03-31',\n",
    "       '2019-04-30', '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31',\n",
    "       '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31', '2020-01-31',\n",
    "       '2020-02-29', '2020-03-31', '2020-04-30', '2020-05-31', '2020-06-30',\n",
    "       '2020-07-31', '2020-08-31', '2020-09-30', '2020-10-31', '2020-11-30',\n",
    "       '2020-12-31', '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n",
    "       '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31', '2021-09-30',\n",
    "       '2021-10-31', '2021-11-30', '2021-12-31', '2022-01-31', '2022-02-28',\n",
    "       '2022-03-31', '2022-04-30', '2022-05-31', '2022-06-30', '2022-07-31',\n",
    "       '2022-08-31', '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31',\n",
    "       '2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30', '2023-05-31',\n",
    "       '2023-06-30', '2023-07-31', '2023-08-31', '2023-09-30'],var_name = 'date',value_name = 'rent')\n",
    "    df_cleaned = df_melt.dropna()\n",
    "    df_cleaned.rename(columns = {'RegionName': 'zipcode'}, inplace = True)\n",
    "    df_cleaned['date'] = pd.to_datetime(df_cleaned['date']).dt.strftime('%Y-%m-%d')\n",
    "    df_cleaned['date'] = pd.to_datetime(df_cleaned['date']).dt.date\n",
    "    df_cleaned.insert(0, \"id\", df_cleaned.index)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b94320",
   "metadata": {},
   "source": [
    "eatra-part: nypd data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7faa38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_nypd_data() -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: A cleaned GeoDataFrame containing NYPD arrest data\n",
    "    \"\"\"\n",
    "    base_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_nypd}?$$app_token={NYC_DATA_APP_TOKEN}\"\n",
    "    url = f'{base_url}&$limit=100000'\n",
    "    download_nyc_geojson_data(url, jsonname = 'nyc_nypd.geojson', force = False)\n",
    "    df = gpd.read_file(DATA_DIR / 'nyc_nypd.geojson')\n",
    "    columns = ['arrest_key', 'arrest_date', 'pd_cd', 'pd_desc', 'age_group', 'geometry']\n",
    "    df_selected = df[columns]\n",
    "    df_cleaned = df_selected.dropna()\n",
    "    return gpd.GeoDataFrame(df_cleaned, geometry = 'geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8cc97",
   "metadata": {},
   "source": [
    "### load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da1eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        A tuple containing GeoDataFrames for all five data\n",
    "    \"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = load_311_data(offset = 1000000)\n",
    "    geodf_tree_data = load_tree_data()\n",
    "    geodf_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "    geodf_nypd_data = download_and_clean_nypd_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        geodf_zillow_data,\n",
    "        geodf_nypd_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ZIPCODE_DATA_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Documents/GitHub/project-group28/project_code.ipynb 单元格 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m geodf_zipcode_data, geodf_311_data, geodf_tree_data, geodf_zillow_data, geodf_nypd_data \u001b[39m=\u001b[39m load_all_data()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/mac/Documents/GitHub/project-group28/project_code.ipynb 单元格 25\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_all_data\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m        A tuple containing GeoDataFrames for all five data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     geodf_zipcode_data \u001b[39m=\u001b[39m load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     geodf_311_data \u001b[39m=\u001b[39m load_311_data(offset \u001b[39m=\u001b[39m \u001b[39m1000000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     geodf_tree_data \u001b[39m=\u001b[39m load_tree_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ZIPCODE_DATA_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, geodf_zillow_data, geodf_nypd_data = load_all_data()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49c4b5",
   "metadata": {},
   "source": [
    "### Get the data info and an outlook of what each datasets look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63417b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geodf_zipcode_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Documents/GitHub/project-group28/project_code.ipynb 单元格 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#Y146sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m geodf_zipcode_data\u001b[39m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geodf_zipcode_data' is not defined"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geodf_zipcode_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Documents/GitHub/project-group28/project_code.ipynb 单元格 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/project-group28/project_code.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m geodf_zipcode_data\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geodf_zipcode_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3373556",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zillow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_nypd_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_nypd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe158af",
   "metadata": {},
   "source": [
    "### Creating databese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ed80d-7b60-484f-a123-23b673b0f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "connection = psycopg2.connect(dbname=\"postgres\",user=DB_USER,host=\"localhost\",port=\"5432\" )\n",
    "connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"CREATE DATABASE {}\".format(DB_NAME))\n",
    "print(f\"create {DB_NAME} sucessfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca11ce4",
   "metadata": {},
   "source": [
    "### Creating extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection1 = psycopg2.connect(dbname=DB_NAME,user=DB_USER,host=\"localhost\",port=\"5432\" )\n",
    "cursor1 = connection1.cursor()\n",
    "cursor1.execute('CREATE EXTENSION postgis;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0cc6-74b3-4d35-a454-57f647c9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nyc_zipcode(\n",
    "    zipcode INTEGER ,\n",
    "    poname VARCHAR,\n",
    "    state VARCHAR,\n",
    "    county VARCHAR,\n",
    "    geometry geometry(Polygon, 4326)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nyc_311(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    date DATE,\n",
    "    zipcode INTEGER,\n",
    "    complaint_type VARCHAR,\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nyc_tree(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    zipcode INTEGER,\n",
    "    spc_common VARCHAR,\n",
    "    health VARCHAR,\n",
    "    status VARCHAR,\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS zillow(\n",
    "    zipcode INTEGER,\n",
    "    date DATE,\n",
    "    rent DECIMAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "indance='''\n",
    "CREATE INDEX idx_geometries_geom_gist ON zipcode USING gist (geometry)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d86f6-ff6e-4bb8-8fa2-df0d4282e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(\"schema.sql\", \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "   \n",
    "    f.write(NYC_311_SCHEMA)\n",
    "  \n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "\n",
    "    f.write(ZILLOW_SCHEMA)\n",
    "    \n",
    "    f.write(indance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"schema.sql\", 'r') as file:\n",
    "    sql_commands = file.read()\n",
    "commands = sql_commands.split(';')\n",
    "\n",
    "for command in commands:\n",
    "    if command.strip(): \n",
    "        print(command)\n",
    "        connection2 = psycopg2.connect(dbname=DB_NAME,user=DB_USER,host=\"localhost\",port=\"5432\" )\n",
    "        cursor2 = connection2.cursor()\n",
    "        cursor2.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b97bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e37800-cd95-44b5-9c21-eb7ac2b2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(DB_USER,DB_NAME):\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\")\n",
    "    geodf_zipcode_data.to_postgis('zipcode', engine, if_exists='append', index=False)\n",
    "    geodf_311_data.to_postgis('nyc_311', engine, if_exists='append', index=False)\n",
    "    geodf_tree_data.to_postgis('nyc_tree', engine, if_exists='append', index=False)\n",
    "    geodf_zillow_data.to_sql('zillow', engine, if_exists='append', index=False)\n",
    "    \n",
    "write_dataframes_to_table(DB_USER,DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "\n",
    "Query 1: Which area might be more calm to live in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(QUERY_1, QUERY_1_FILENAME):\n",
    "    with open (QUERY_1_FILENAME,'w')as f:\n",
    "        f.write(QUERY_1)\n",
    "        f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605e6f3-ec42-4a8b-833c-5138c14b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"query1\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce044adf-ecdf-4237-9b20-b7cdaaab0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b6daf",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "\n",
    "Query 2: Where has the most greenery?\n",
    "Zipcode\n",
    "tree_id\n",
    "Using just the trees table, which 10 zip codes have the most trees?\n",
    "\n",
    "The query result should have two columns, 10 rows. The rows should be sorted by the total number of trees, descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"query2\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee45766",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101325e6",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "\n",
    "\n",
    "Query 3: Can I afford a place in the areas with the most trees?\n",
    "Zillow_rent\n",
    "RegionName, 2023-08-31\n",
    "\n",
    "\n",
    "Of the 10 zip codes with the most trees, for the month of August 2023, what is the average rent by zip code?\n",
    "\n",
    "The query should have a JOIN statement. The query result should have two columns (not three) and 10 rows. The rows should be sorted by the total number of trees, descending. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"query3\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb121a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40630d",
   "metadata": {},
   "source": [
    "### Query4\n",
    "Query 4: Could there be a correlation between an area’s rent, the number of its trees, and the number of 311 complaints?\n",
    "2023-1\n",
    "For the month of January 2023, return the 5 zip codes with the lowest average rent, and 5 zipcodes of the highest average rent, and include the tree count and complaint count for each zip code by using JOIN statements.\n",
    "\n",
    "The query result should have 4 columns (zip code, average rent, tree count, and complaint count) and 10 rows: five with the highest average rent, and five with the lowest average rent. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR / \"query4\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6dcd3",
   "metadata": {},
   "source": [
    "### Query 5\n",
    "\n",
    "Query 5: Where has the most greenery (take 2)?\n",
    "Rewrite Query 2 to use both the trees table and the zipcodes table. Join both tables where the coordinate point of the tree is inside the polygon boundary of the zipcode as defined in the zipcode table.\n",
    "\n",
    "\n",
    "\n",
    "The query should have a JOIN statement. The query results should match exactly the results of Query 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765aed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR / \"query5\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b08bde",
   "metadata": {},
   "source": [
    "### Query 6\n",
    "\n",
    "Using the following coordinate pair on campus, which trees are within ½ mile radius of this\n",
    "point?\n",
    "Latitude: 40.80737875669467, Longitude: -73.96253174434912\n",
    "Tree: longitude, latitude, tree_id, spc_common, health, status, x_sp, y_sp\n",
    "The result should have 5 columns (ID, species, health, status, and coordinate location of each\n",
    "tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1071f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = QUERY_DIR / \"query6\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4 (main, Jul  5 2023, 08:54:11) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "228b5ecbca0a52b26ffadd660c38e462f6911db7b10539fb271c7c5e05201501"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
